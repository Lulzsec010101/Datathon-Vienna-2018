{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, RegexTokenizer, StopWordsRemover, CountVectorizer\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql import DataFrameWriter\n",
    "from pyspark.ml.linalg import Vectors, SparseVector\n",
    "from pyspark.ml.clustering import LDA\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "import pandas as pd\n",
    "\n",
    "db = \"sm\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets_sdf = spark.sql(\"SELECT status_id, textTranslated AS text FROM \" + db + \".twitter\")\n",
    "df = spark.sql(\"SELECT status_id, text FROM \" + db + \".twitter WHERE lang = 'en'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "regexTokenizer = RegexTokenizer(inputCol=\"text\", outputCol=\"words\", pattern=\"\\\\W\", minTokenLength=4, \n",
    "                                toLowercase=True)\n",
    "df = regexTokenizer.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
    "df = remover.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+--------------------+--------------------+\n",
      "|         status_id|                text|               words|            filtered|\n",
      "+------------------+--------------------+--------------------+--------------------+\n",
      "|972175221481459712|When your wonderf...|[when, your, wond...|[wonderful, frien...|\n",
      "|972082111606939648|@GrandHuit Rettet...|[grandhuit, rette...|[grandhuit, rette...|\n",
      "|973220871551807490|\"The melon patent...|[melon, patent, p...|[melon, patent, p...|\n",
      "|971416727862108160|@NoPatentsOnSeed ...|[nopatentsonseed,...|[nopatentsonseed,...|\n",
      "|973337751893479424|@BigCatRescue @Th...|[bigcatrescue, th...|[bigcatrescue, th...|\n",
      "|972073473559420929|How can we achiev...|[achieve, equalit...|[achieve, equalit...|\n",
      "|972052286439600129|Could a fish be s...|[could, fish, sai...|[fish, said, sust...|\n",
      "|970597439383261184|@MareMundi Super ...|[maremundi, super...|[maremundi, super...|\n",
      "|970366504293273600|Today, 30 years a...|[today, years, vi...|[today, years, vi...|\n",
      "|970254178667855872|Happy 30th Bday @...|[happy, 30th, bda...|[happy, 30th, bda...|\n",
      "|970240136410693632|Who is behind IWA...|[behind, iwas, in...|[behind, iwas, in...|\n",
      "|970236661392138240|Happy bday @VIERP...|[happy, bday, vie...|[happy, bday, vie...|\n",
      "|970211668130238464|Gratulation, lieb...|[gratulation, lie...|[gratulation, lie...|\n",
      "|972393251180351488|@VCOE_AT @SPIEGEL...|[vcoe_at, spiegel...|[vcoe_at, spiegel...|\n",
      "|972043961081782273|no matter how you...|[matter, twist, t...|[matter, twist, t...|\n",
      "|971707912488914944|Time to celebrate...|[time, celebrate,...|[time, celebrate,...|\n",
      "|971387478237220865|We have the right...|[have, right, kno...|[right, know, buy...|\n",
      "|971037462511472640|Overfishing, eutr...|[overfishing, eut...|[overfishing, eut...|\n",
      "|971035770487222272|New #WWFScorecard...|[wwfscorecard, sh...|[wwfscorecard, sh...|\n",
      "|970935767429238784|Learn the uncomfo...|[learn, uncomfort...|[learn, uncomfort...|\n",
      "+------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|         status_id|                text|               words|            filtered|            features|\n",
      "+------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|972175221481459712|When your wonderf...|[when, your, wond...|[wonderful, frien...|(100,[0,19,48],[1...|\n",
      "|972082111606939648|@GrandHuit Rettet...|[grandhuit, rette...|[grandhuit, rette...|     (100,[0],[1.0])|\n",
      "|973220871551807490|\"The melon patent...|[melon, patent, p...|[melon, patent, p...|     (100,[0],[1.0])|\n",
      "|971416727862108160|@NoPatentsOnSeed ...|[nopatentsonseed,...|[nopatentsonseed,...|         (100,[],[])|\n",
      "|973337751893479424|@BigCatRescue @Th...|[bigcatrescue, th...|[bigcatrescue, th...|         (100,[],[])|\n",
      "|972073473559420929|How can we achiev...|[achieve, equalit...|[achieve, equalit...|(100,[0,22],[1.0,...|\n",
      "|972052286439600129|Could a fish be s...|[could, fish, sai...|[fish, said, sust...|(100,[0,86],[1.0,...|\n",
      "|970597439383261184|@MareMundi Super ...|[maremundi, super...|[maremundi, super...|         (100,[],[])|\n",
      "|970366504293273600|Today, 30 years a...|[today, years, vi...|[today, years, vi...|(100,[0,32,69],[1...|\n",
      "|970254178667855872|Happy 30th Bday @...|[happy, 30th, bda...|[happy, 30th, bda...|     (100,[0],[1.0])|\n",
      "|970240136410693632|Who is behind IWA...|[behind, iwas, in...|[behind, iwas, in...|(100,[0,32],[2.0,...|\n",
      "|970236661392138240|Happy bday @VIERP...|[happy, bday, vie...|[happy, bday, vie...|(100,[0,19,74],[1...|\n",
      "|970211668130238464|Gratulation, lieb...|[gratulation, lie...|[gratulation, lie...|     (100,[0],[1.0])|\n",
      "|972393251180351488|@VCOE_AT @SPIEGEL...|[vcoe_at, spiegel...|[vcoe_at, spiegel...|     (100,[0],[1.0])|\n",
      "|972043961081782273|no matter how you...|[matter, twist, t...|[matter, twist, t...|     (100,[0],[2.0])|\n",
      "|971707912488914944|Time to celebrate...|[time, celebrate,...|[time, celebrate,...|(100,[0,31],[1.0,...|\n",
      "|971387478237220865|We have the right...|[have, right, kno...|[right, know, buy...|(100,[30,53,78],[...|\n",
      "|971037462511472640|Overfishing, eutr...|[overfishing, eut...|[overfishing, eut...|     (100,[0],[1.0])|\n",
      "|971035770487222272|New #WWFScorecard...|[wwfscorecard, sh...|[wwfscorecard, sh...|(100,[0,52],[1.0,...|\n",
      "|970935767429238784|Learn the uncomfo...|[learn, uncomfort...|[learn, uncomfort...|(100,[0,73],[1.0,...|\n",
      "+------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(inputCol=\"filtered\", outputCol=\"features\", vocabSize=100, minDF=10.0)\n",
    "model = cv.fit(df)\n",
    "model.transform(df).show()\n",
    "df = model.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cv.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_local = pd.DataFrame(model.vocabulary, columns = [\"word\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>islam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>immigration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>muslim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>migration</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word\n",
       "0        https\n",
       "1        islam\n",
       "2  immigration\n",
       "3       muslim\n",
       "4    migration"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_local.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+\n",
      "|         status_id|            features|\n",
      "+------------------+--------------------+\n",
      "|972175221481459712|(100,[0,19,48],[1...|\n",
      "|972082111606939648|     (100,[0],[1.0])|\n",
      "|973220871551807490|     (100,[0],[1.0])|\n",
      "|971416727862108160|         (100,[],[])|\n",
      "|973337751893479424|         (100,[],[])|\n",
      "|972073473559420929|(100,[0,22],[1.0,...|\n",
      "|972052286439600129|(100,[0,86],[1.0,...|\n",
      "|970597439383261184|         (100,[],[])|\n",
      "|970366504293273600|(100,[0,32,69],[1...|\n",
      "|970254178667855872|     (100,[0],[1.0])|\n",
      "|970240136410693632|(100,[0,32],[2.0,...|\n",
      "|970236661392138240|(100,[0,19,74],[1...|\n",
      "|970211668130238464|     (100,[0],[1.0])|\n",
      "|972393251180351488|     (100,[0],[1.0])|\n",
      "|972043961081782273|     (100,[0],[2.0])|\n",
      "|971707912488914944|(100,[0,31],[1.0,...|\n",
      "|971387478237220865|(100,[30,53,78],[...|\n",
      "|971037462511472640|     (100,[0],[1.0])|\n",
      "|971035770487222272|(100,[0,52],[1.0,...|\n",
      "|970935767429238784|(100,[0,73],[1.0,...|\n",
      "+------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=df.drop('text', 'words','filtered')\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LDA(k=10, maxIter=10)\n",
    "model = lda.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+\n",
      "|topic|         termIndices|         termWeights|\n",
      "+-----+--------------------+--------------------+\n",
      "|    0|[20, 18, 1, 0, 65...|[0.12914028153688...|\n",
      "|    1|[0, 2, 1, 31, 69,...|[0.18396579659795...|\n",
      "|    2|[2, 0, 11, 9, 15,...|[0.30149179928421...|\n",
      "|    3|[0, 1, 12, 16, 42...|[0.22684828921016...|\n",
      "|    4|[10, 39, 52, 1, 0...|[0.30393725650092...|\n",
      "|    5|[1, 5, 0, 8, 49, ...|[0.25417454693979...|\n",
      "|    6|[1, 0, 22, 3, 19,...|[0.19677070507123...|\n",
      "|    7|[0, 4, 2, 29, 45,...|[0.39747374003316...|\n",
      "|    8|[0, 1, 26, 13, 9,...|[0.19733309422827...|\n",
      "|    9|[0, 1, 3, 7, 6, 1...|[0.31556296399376...|\n",
      "+-----+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.describeTopics().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark2",
   "language": "python",
   "name": "anaconda-pyspark2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
